{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00000-bce72383-935d-43c9-8165-a01274f0e6d4",
    "deepnote_cell_type": "code",
    "execution_millis": 1767,
    "execution_start": 1608328645444,
    "output_cleared": false,
    "source_hash": "205c31cf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import inspect\n",
    "import pandas as pd\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.data_gen import generate_regression_outputs\n",
    "from utils.models import BNN_LV, BayesianModel, SamplerModel\n",
    "from utils.training import BBVI\n",
    "\n",
    "# Import helpers for building Weights & Biases callbacks:\n",
    "from utils.training import build_wb_callback_postpred, build_wb_callback_plotfunc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-f6e5f7b9-756e-4d42-b8dd-788b79e8a412",
    "deepnote_cell_type": "code",
    "execution_millis": 40,
    "execution_start": 1608328649001,
    "output_cleared": false,
    "source_hash": "491edcae",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "Y_train, X_train = generate_regression_outputs(type='hsc')\n",
    "X_test = np.linspace(-6,6, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00003-78d6d1f0-23d8-4009-95c4-2bb88cc178e3",
    "deepnote_cell_type": "code",
    "execution_millis": 93012,
    "execution_start": 1608328707296,
    "output_cleared": false,
    "source_hash": "3c27484c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Bayesian Neural Network with Latent Variable (BNN_LV):\n",
    "L = 1\n",
    "N, M = X_train.shape  # Input shape.\n",
    "_, K = Y_train.shape  # Output shape.\n",
    "gamma = 1.0  # Standard deviation of noise for each latent input.\n",
    "sigma = 1.0  # Standard evation of noise on each model output.\n",
    "\n",
    "# Newtork architecture:\n",
    "architecture = {\n",
    "    'input_n' : M,  # 1 output.\n",
    "    'output_n' : K,  # 1 input.\n",
    "    'hidden_layers' : [20,20],\n",
    "    'biases' : [1,1,1],\n",
    "    'activations' : ['relu', 'relu', 'linear'],\n",
    "    'gamma' : [gamma]*L,\n",
    "    'sigma' : [sigma]*K,\n",
    "    'seed' : 207,\n",
    "}\n",
    "\n",
    "# Initialize network:\n",
    "bnn_lv = BNN_LV(architecture=architecture)\n",
    "\n",
    "# Get number of weights in network:\n",
    "D = bnn_lv.D\n",
    "\n",
    "# Train network to get MLE estimate as starting point for sampler:\n",
    "bnn_lv.fit(X_train, Y_train, step_size=0.01, max_iteration=5000, check_point=500, regularization_coef=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00003-ac1bc9dc-914d-47cb-a91d-ed1457c5934f",
    "deepnote_cell_type": "code",
    "execution_millis": 0,
    "execution_start": 1608329050148,
    "output_cleared": false,
    "source_hash": "cee72afd"
   },
   "outputs": [],
   "source": [
    "# Define Bayesian model (with a posterior on W and Z):\n",
    "bayesian_model = BayesianModel(\n",
    "    X = X_train,\n",
    "    Y = Y_train,\n",
    "    nn = bnn_lv,\n",
    "    prior_weights_mean = 0,\n",
    "    prior_weights_stdev = 5.0,\n",
    "    prior_latents_mean = 0,\n",
    "    prior_latents_stdev = gamma,\n",
    "    likelihood_stdev = 0.25,\n",
    "    output_noise_stdev = sigma,\n",
    "    label = 'Toy example with heteroscedastic noise',\n",
    ")\n",
    "# Wrap the model so that it takes a single input (`samples`) that stores both W and Z:\n",
    "sampler_model = SamplerModel(bayesian_model)\n",
    "\n",
    "sampler_model.display()\n",
    "sampler_model.describe()\n",
    "sampler_model.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00004-7711d690-fc25-4452-b4c9-e03e11f6da8a",
    "deepnote_cell_type": "code",
    "execution_millis": 28204,
    "execution_start": 1608329511212,
    "output_cleared": false,
    "scrolled": false,
    "source_hash": "4e3aee7f"
   },
   "outputs": [],
   "source": [
    "# Create the posterior :\n",
    "log_posterior = sampler_model.log_posterior\n",
    "\n",
    "# Get the MLE starting weights from the fitted network:\n",
    "mle_weights = bnn_lv.get_weights()\n",
    "\n",
    "# Concatenate means for W and Z into a single init vector:\n",
    "W_mean_init = mle_weights.reshape(1,-1)\n",
    "Z_mean_init = np.zeros((N,1))\n",
    "Mu_init = sampler_model.stack(W_mean_init, Z_mean_init)\n",
    "\n",
    "# Concatenate covariances for W and Z into a single init vector:\n",
    "W_var_init = np.ones((1,D)) ** 2\n",
    "Z_var_init = np.ones((N,1))*gamma ** 2\n",
    "Sigma_init = sampler_model.stack(W_var_init, Z_var_init)\n",
    "\n",
    "# Build a callback that produces a scatter plot using W&B built-in functions:\n",
    "wb_callback_postpred_wandb = build_wb_callback_postpred(sampler_model, x_data=X_test, mode='wandb', interval=50)\n",
    "wb_callback_postpred_pyplot = build_wb_callback_postpred(sampler_model, x_data=X_test, mode='pyplot', interval=50)\n",
    "\n",
    "# Define W&B settings:\n",
    "wb_settings = {\n",
    "    'entity' : 'gpestre',\n",
    "    'project' : 'am207',\n",
    "    'group' : 'hsc_bbvi',\n",
    "    'name' : 'hsc_bbvi_v1',\n",
    "    'notes' : 'BBVI on toy dataset with heteroscedastic noise.',\n",
    "    'progress' : 10,\n",
    "    'base_path' : '../data/',\n",
    "    'filename' : 'hsc_bbvi_state.json',\n",
    "    'archive' : {  # Manually archive info about network and priors.\n",
    "        'architecture' : architecture,\n",
    "        'N' : N,\n",
    "        'M' : M,\n",
    "        'K' : K,\n",
    "        'L' : L,\n",
    "        'D' : D,\n",
    "        'gamma' : gamma,\n",
    "        'sigma' : sigma,\n",
    "        'Mu_init' : Mu_init,\n",
    "        'Sigma_init' : Sigma_init,\n",
    "    },\n",
    "    'callback' : [\n",
    "        wb_callback_postpred_wandb,\n",
    "        wb_callback_postpred_pyplot,\n",
    "    ],\n",
    "}\n",
    "\n",
    "# BBVI settings:\n",
    "bbvi_params = {\n",
    "    'num_samples' : 500,\n",
    "    'step_size' : 0.001,\n",
    "    'num_iters' : 2_000,\n",
    "    'random_seed' : 207,\n",
    "    'Mu_init' : Mu_init,\n",
    "    'Sigma_init' : Sigma_init,\n",
    "    'wb_settings' : wb_settings,\n",
    "}\n",
    "\n",
    "# Perform BBVI:\n",
    "bbvi = BBVI(log_posterior, **bbvi_params, progress=100)\n",
    "Mu, Sigma = bbvi.run()\n",
    "\n",
    "# Plot optimization history:\n",
    "title = \"BBVI: \" + sampler_model.label if sampler_model.label is not None else \"\"\n",
    "elbo_hist = bbvi.elbo_hist\n",
    "mag_hist = bbvi.magnitude_hist\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(16,5))\n",
    "fig.suptitle(title, fontsize=20)\n",
    "ax1.plot(range(1,1+len(elbo_hist)),elbo_hist)\n",
    "ax1.set_xlabel(\"Iteration\", fontsize=14)\n",
    "ax1.set_ylabel(\"ELBO\", fontsize=14)\n",
    "ax2.plot(range(1,1+len(mag_hist)),mag_hist)\n",
    "ax2.set_xlabel(\"Iteration\", fontsize=14)\n",
    "ax2.set_ylabel(\"Magnitude of gradient\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-b510e3c5-19e7-4f8b-8c47-73f7ee843c60",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Get training data and define test values:\n",
    "x_test = X_test.flatten()\n",
    "x_train = sampler_model.X.flatten()\n",
    "y_train = sampler_model.Y.flatten()\n",
    "samples = hmc.get_samples()\n",
    "S = samples.shape[0]\n",
    "Y_pred = sampler_model.predict(X=x_test.reshape(-1,1), samples=samples).reshape(S,-1)\n",
    "\n",
    "# Calculate percentiles\n",
    "y_lower = np.percentile(Y_pred, q=2.5, axis=0)\n",
    "y_upper = np.percentile(Y_pred, q=97.5, axis=0)\n",
    "y_med = np.percentile(Y_pred, q=50, axis=0)\n",
    "\n",
    "# Plot with confidence\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.scatter(x_train, y_train, color='black', label='data')\n",
    "plt.plot(x_test, y_med, label=\"Median Prediction\")\n",
    "plt.fill_between(x_test, y_lower, y_upper, alpha=0.4, color='r', label=\"95% Predictive Interval\")\n",
    "plt.title(\"Bayesian Neural Net Predictions with 95% CI\")\n",
    "plt.xlabel(\"X Test\")\n",
    "plt.ylabel(\"Y Predicted\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-a8151c20-811e-4f06-9142-a3437e5aa7fd",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "7c7d0858-4b5b-4cdc-ba76-8541e59df731",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
