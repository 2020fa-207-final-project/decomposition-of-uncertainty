{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00000-bce72383-935d-43c9-8165-a01274f0e6d4",
    "deepnote_cell_type": "code",
    "execution_millis": 489,
    "execution_start": 1607707847982,
    "output_cleared": false,
    "source_hash": "a52b2e37",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from utils.models import BNN, BNN_LV\n",
    "from utils.functions import gaussian, log_gaussian\n",
    "from utils.training import BBVI\n",
    "from utils.data_gen import sample_gaussian_mixture, generate_regression_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-f6e5f7b9-756e-4d42-b8dd-788b79e8a412",
    "deepnote_cell_type": "code",
    "execution_millis": 19,
    "execution_start": 1607707849356,
    "output_cleared": false,
    "source_hash": "d613305c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "Y_hsc, X_hsc = generate_regression_outputs(type='hsc')\n",
    "X_test = np.linspace(-6,6, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00002-80ec7d1f-11c7-41e0-81f3-540fa96fe63e",
    "deepnote_cell_type": "code",
    "execution_millis": 14,
    "execution_start": 1607707850890,
    "output_cleared": false,
    "source_hash": "b801ef8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the prior, likelihood and posterior\n",
    "def log_prior(W, mu, sigma):\n",
    "    \"\"\" Generate the prior PDF \"\"\"\n",
    "    return np.sum(log_gaussian(x=W, mu=mu, sigma=sigma), axis=-1)\n",
    "\n",
    "# Set up the prior, likelihood and posterior\n",
    "def log_latent_prior(Z, mu, gamma):\n",
    "    \"\"\" Generate the prior PDF \"\"\"\n",
    "    return np.sum(np.sum(log_gaussian(x=Z, mu=mu, sigma=gamma), axis=-1), axis=-1)\n",
    "\n",
    "def log_likelihood(W, X, Y, mu, sigma):\n",
    "    \"\"\" Generate the likelihood PDF \"\"\"\n",
    "    llh = np.sum(log_gaussian(x=Y, mu=mu, sigma=sigma), axis=0)\n",
    "    return llh\n",
    "\n",
    "def create_log_posterior(X, Y, p_mu, p_sigma, l_sigma, nn, gamma, L=1):\n",
    "    \"\"\"\n",
    "    Wrapper to create an initialized posterior PDF.\n",
    "    \"\"\"\n",
    "    # Check dimensions:\n",
    "    assert len(X.shape)==2, \"Expects X to be 2 dimensional (N by M).\"\n",
    "    assert len(Y.shape)==2, \"Expects Y to be 2 dimensional (N by K).\"\n",
    "    N,M = X.shape\n",
    "    _,K = Y.shape\n",
    "    assert Y.shape[0]==N, f\"X and Y should have the same number of rows ({N}).\"\n",
    "    # Define single input version (used in wrapper functions below):\n",
    "    def _log_posterior(W, Z, X=X, Y=Y, p_mu=p_mu, p_sigma=p_sigma, l_sigma=l_sigma, nn=nn, gamma=gamma, L=L):\n",
    "        \"\"\"\n",
    "        2D version of posterior.\n",
    "        \"\"\"\n",
    "        # Get the densities of the priors on W and Z:\n",
    "        log_pri_weights = log_prior(W=W, mu=p_mu, sigma=p_sigma)\n",
    "        log_pri_latents = log_latent_prior(Z=Z, mu=0, gamma=gamma)\n",
    "        # Perform a forward pass and use the result as the mean of the likelihood:\n",
    "        mu_l = nn.forward(X, weights=W, input_noise=Z)\n",
    "        log_lhood = log_likelihood(W=W, X=X, Y=Y, mu=mu_l, sigma=l_sigma)\n",
    "        # Return log posterior:\n",
    "        log_post = log_pri_weights + log_pri_latents + log_lhood\n",
    "        return log_post\n",
    "    # Define a wrapper for the posterior that can handle 2D or 3D case:\n",
    "    def log_posterior(W, Z, X=X, Y=Y, p_mu=p_mu, p_sigma=p_sigma, l_sigma=l_sigma, nn=nn, gamma=gamma, L=L):\n",
    "        \"\"\"\n",
    "        Posterior of W and Z (which can handle 2D or 3D version of Z).\n",
    "        \"\"\"\n",
    "        # Check dimensions:\n",
    "        assert len(W.shape)==2, \"Expects W to be 2 dimensional (S by D).\"\n",
    "        assert len(Z.shape) in {2,3}, \"Expects Z to be 2 dimensional (N by L) or 3 dimensional (S by N by L).\"\n",
    "        assert Z.shape[-2]==N, f\"Unexpected shape of Z ({Z.shape}); doesn't match number of observations ({N}).\"\n",
    "        assert Z.shape[-1]==L, f\"Unexpected shape of Z ({Z.shape}); doesn't match number of latent features ({L}).\"\n",
    "        assert W.shape[1]==nn.D, f\"The columns of W ({W.shape[1]}) should match the number of weights ({nn.D}).\"\n",
    "        # Special case where there are S sets of weights and S sets of Z values:\n",
    "        if len(Z.shape)==3 and (Z.shape[0]==W.shape[0]):\n",
    "            # Collect vector of S results:\n",
    "            results = np.array([\n",
    "               _log_posterior(\n",
    "                   w.reshape(1,-1), z,   # Should be  1 by D  and  N by L respectively.\n",
    "                   X=X, Y=Y, p_mu=p_mu, p_sigma=p_sigma, l_sigma=l_sigma, nn=nn, gamma=gamma, L=L,\n",
    "               )\n",
    "                for w,z in zip(W,Z)\n",
    "            ])\n",
    "            return np.array(results).flatten()\n",
    "        # Regular case:\n",
    "        result = _log_posterior(W, Z, X=X, Y=Y, p_mu=p_mu, p_sigma=p_sigma, l_sigma=l_sigma, nn=nn, gamma=gamma, L=L)\n",
    "        return result\n",
    "        \n",
    "    return log_posterior\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00003-78d6d1f0-23d8-4009-95c4-2bb88cc178e3",
    "deepnote_cell_type": "code",
    "execution_millis": 124523,
    "execution_start": 1607707897550,
    "output_cleared": false,
    "source_hash": "a68473d1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters -- network:\n",
    "N, M = X_hsc.shape  # Input shape.\n",
    "_, K = Y_hsc.shape  # Output shape.\n",
    "\n",
    "# Hyperparameters -- latent variables:\n",
    "L = 1  # Number of latent features (inputs)\n",
    "gamma = 1\n",
    "sigma = 1\n",
    "\n",
    "# Newtork architecture:\n",
    "architecture = {\n",
    "    'input_n' : M,  # 1 output.\n",
    "    'output_n' : K,  # 1 input.\n",
    "    'hidden_layers' : [3,3],\n",
    "    'biases' : [1,1,1],\n",
    "    'activations' : ['relu', 'relu', 'linear'],\n",
    "    'gamma' : [gamma]*L,  # Repeated for each latent input.\n",
    "    'sigma' : [sigma]*K,  # Repeated for each network output.\n",
    "}\n",
    "\n",
    "# Initialize network:\n",
    "bnn_lv = BNN_LV(architecture=architecture)\n",
    "\n",
    "# Get number of weights in network:\n",
    "D = bnn_lv.D\n",
    "\n",
    "# Train network:\n",
    "bnn_lv.fit(X_hsc, Y_hsc, step_size=0.01, max_iteration=5000, check_point=500, regularization_coef=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import helpers for building callbacks:\n",
    "from utils.training import build_wb_callback_postpred\n",
    "from utils.training import build_wb_callback_plotfunc\n",
    "\n",
    "# Build a callback that produces a scatter plot using W&B built-in functions:\n",
    "wb_callback_postpred = build_wb_callback_postpred(model=bnn_lv, x_data=X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00004-c98ef9ff-107c-4c3e-9c7e-15eafb61fd94",
    "deepnote_cell_type": "code",
    "execution_millis": 46203,
    "execution_start": 1607708059455,
    "output_cleared": false,
    "source_hash": "abdbfbe6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the posterior :\n",
    "log_posterior_hsc = create_log_posterior(X_hsc, Y_hsc, 0, 5, 0.25, bnn_lv, gamma=gamma, L=1)\n",
    "\n",
    "# Get the MLE starting weights from the fitted network:\n",
    "mle_weights = bnn_lv.get_weights()\n",
    "\n",
    "# Define BBVI starting point for NN weights:\n",
    "Mu_init      = mle_weights\n",
    "Sigma_init   = np.ones(D)\n",
    "\n",
    "# Define BBVI starting point latent variables (one per data obervation):\n",
    "Mu_init_Z    = np.zeros(N)\n",
    "Sigma_init_Z = np.ones(N)*gamma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define W&B settings:\n",
    "wb_settings = {\n",
    "    'entity' : 'gpestre',\n",
    "    'project' : 'am207',\n",
    "    'group' : 'tests',\n",
    "    'name' : 'bbvi_test',\n",
    "    'notes' : 'BBVI test',\n",
    "    'progress' : 10,\n",
    "#     'base_path' : '../data/',\n",
    "#     'filename' : 'temp_bbvi_state.json',\n",
    "    'archive' : {  # Manually archive info about network and priors.\n",
    "        'architecture' : architecture,\n",
    "        'N' : N,\n",
    "        'M' : M,\n",
    "        'K' : K,\n",
    "        'L' : L,\n",
    "        'D' : D,\n",
    "        'gamma' : gamma,\n",
    "        'sigma' : sigma,\n",
    "        'Mu_init' : Mu_init,\n",
    "        'Sigma_init' : Sigma_init,\n",
    "        'Mu_init_Z' : Mu_init_Z,\n",
    "        'Sigma_init_Z' : Sigma_init_Z,\n",
    "    },\n",
    "    #'callback' : [wb_callback_postpred],\n",
    "}\n",
    "\n",
    "# BBVI settings:\n",
    "bbvi_params_hsc = {\n",
    "    'mode' : 'BNN_LV',\n",
    "    'num_samples' : 100,\n",
    "    'step_size' : 0.001,\n",
    "    'num_iters' : 100,\n",
    "    'random_seed' : 207,\n",
    "    'Mu_init' : Mu_init,\n",
    "    'Sigma_init' : Sigma_init,\n",
    "    'Mu_init_Z' : Mu_init_Z,\n",
    "    'Sigma_init_Z' : Sigma_init_Z,\n",
    "    'wb_settings' : wb_settings,\n",
    "}\n",
    "\n",
    "# Perform BBVI:\n",
    "bbvi_hsc = BBVI(log_posterior_hsc, **bbvi_params_hsc, progress=10)\n",
    "Mu, Sigma = bbvi_hsc.run()\n",
    "\n",
    "# Plot optimization history:\n",
    "elbo_hist = bbvi_hsc.elbo_hist\n",
    "mag_hist = bbvi_hsc.magnitude_hist\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(16,5))\n",
    "fig.suptitle(\"BBVI on Benchmark\", fontsize=20)\n",
    "ax1.plot(range(1,1+len(elbo_hist)),elbo_hist)\n",
    "ax1.set_xlabel(\"Iteration\", fontsize=14)\n",
    "ax1.set_ylabel(\"ELBO\", fontsize=14)\n",
    "ax2.plot(range(1,1+len(mag_hist)),mag_hist)\n",
    "ax2.set_xlabel(\"Iteration\", fontsize=14)\n",
    "ax2.set_ylabel(\"Magnitude of gradient\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00005-99ef656d-4535-4498-b261-bb1262d2998b",
    "deepnote_cell_type": "code",
    "execution_millis": 1652,
    "execution_start": 1607702557516,
    "output_cleared": false,
    "source_hash": "8187639b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Set up data\n",
    "# x_test = np.linspace(-6, 6, 100)\n",
    "\n",
    "# # Take 100 random posterior samples\n",
    "# w_random_samples = bayesian_lv_weights[np.random.choice(bayesian_lv_weights.shape[0], 10000), :]\n",
    "\n",
    "# y_preds = []\n",
    "\n",
    "# # Loop through the samples of weights\n",
    "# for i in range(w_random_samples.shape[0]):\n",
    "#     # Create the same NN for predictions but with weights from the samples\n",
    "#     w_cur = w_random_samples[i,:]\n",
    "\n",
    "#     mu_pred = bnn_lv.forward(x_test.reshape(-1,1), w_cur)\n",
    "#     y_pred = mu_pred\n",
    "#     y_preds.append(y_pred.reshape(-1))\n",
    "\n",
    "# # Calculate percentiles\n",
    "# y_lower = np.percentile(y_preds, q=2.5, axis=0)\n",
    "# y_upper = np.percentile(y_preds, q=97.5, axis=0)\n",
    "# y_med = np.percentile(y_preds, q=50, axis=0)\n",
    "\n",
    "# # Plot with confidence\n",
    "# plt.figure(figsize=(14,7))\n",
    "# plt.scatter(X_hsc.flatten(), y_hsc.flatten(), color='black', label='data')\n",
    "# plt.plot(x_test, y_med, label=\"Median Prediction\")\n",
    "# plt.fill_between(x_test, y_lower, y_upper, alpha=0.4, color='r', label=\"95% Predictive Interval\")\n",
    "# plt.title(\"Bayesian Neural Net Predictions with 95% CI\")\n",
    "# plt.xlabel(\"X Test\")\n",
    "# plt.ylabel(\"Y Predicted\")\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "7c7d0858-4b5b-4cdc-ba76-8541e59df731",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
